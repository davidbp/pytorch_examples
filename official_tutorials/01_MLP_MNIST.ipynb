{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#From-np.ndarray-to-torch.Tensor\" data-toc-modified-id=\"From-np.ndarray-to-torch.Tensor-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>From <code>np.ndarray</code> to <code>torch.Tensor</code></a></span></li><li><span><a href=\"#Training-a-model-manually-defining-batches\" data-toc-modified-id=\"Training-a-model-manually-defining-batches-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Training a model manually defining batches</a></span></li><li><span><a href=\"#Defining-TensorDatset-and-DataLoader\" data-toc-modified-id=\"Defining-TensorDatset-and-DataLoader-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Defining <code>TensorDatset</code> and <code>DataLoader</code></a></span></li><li><span><a href=\"#Training-with-a-DataLoader-instance\" data-toc-modified-id=\"Training-with-a-DataLoader-instance-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training with a <code>DataLoader</code> instance</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:33.324275Z",
     "start_time": "2020-12-09T09:59:32.159257Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:36.360826Z",
     "start_time": "2020-12-09T09:59:33.326481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../input/train.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:36.779090Z",
     "start_time": "2020-12-09T09:59:36.363519Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df['label'].values\n",
    "X = df.drop(['label'],1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:36.783413Z",
     "start_time": "2020-12-09T09:59:36.780492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35700, 784)\n",
      "(6300,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From `np.ndarray` to `torch.Tensor`\n",
    "\n",
    "One of the most basic methods that we need to benefit from pytorch is the capability to translate `np.ndarray` objects to `torch.Tensor` objects\n",
    "\n",
    "- **`torch.from_numpy(X)`** creates a `torch.Tensor` from a `np.darray` object `X`\n",
    "\n",
    "\n",
    "- **`torch.from_numpy(X).dtype(torch.LongTensor)`** creates a `torch.Tensor` from a `np.darray` object `X` and casts this object as `torch.LongTensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:36.789908Z",
     "start_time": "2020-12-09T09:59:36.785073Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)   # data type is long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:36.800406Z",
     "start_time": "2020-12-09T09:59:36.791892Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_X_train.dtype, torch_y_train.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model manually defining batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:36.808903Z",
     "start_time": "2020-12-09T09:59:36.802327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To train a model in a given minibatch we need:\n",
    "    \n",
    "- The model for the minibatch, store the results in `y_hat`.\n",
    "\n",
    "\n",
    "- A loss function, in this case we will use `nn.CrossEntropyLoss()`\n",
    "\n",
    "\n",
    "- The error between `y_hat_batch` and `y_batch`.\n",
    "     - Note that the error is computed using `var_y_batch` which is a simple cast\n",
    "       from numpy array to `torch.Tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:36.817697Z",
     "start_time": "2020-12-09T09:59:36.811076Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(model, X_train, y_train, batch_size):\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 2\n",
    "    model.train()\n",
    "    n_examples, n_features = X_train.shape\n",
    "    n_batches_per_epoch = int(np.ceil(n_examples/batch_size))\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx in range(n_batches_per_epoch):\n",
    "            start_pos = batch_idx * batch_size\n",
    "            end_pos = start_pos + batch_size\n",
    "            X_batch = X_train[start_pos:end_pos]\n",
    "            y_batch = y_train[start_pos:end_pos]\n",
    "            \n",
    "            # X_batch.shape -> torch.Size([32, 784])\n",
    "            var_X_batch = Variable(X_batch).float() \n",
    "            # y_batch.shape -> torch.Size([32]) \n",
    "            var_y_batch = Variable(y_batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(var_X_batch)\n",
    "            loss = error(y_hat, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(y_hat.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "\n",
    "            #print(correct)\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), n_examples, \n",
    "                    100.*batch_idx /n_examples, loss.data.item(),\n",
    "                    float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.491876Z",
     "start_time": "2020-12-09T09:59:36.819669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 13.100049\t Accuracy:9.375%\n",
      "Epoch : 0 [1600/35700 (0%)]\tLoss: 0.697478\t Accuracy:68.137%\n",
      "Epoch : 0 [3200/35700 (0%)]\tLoss: 1.099457\t Accuracy:76.300%\n",
      "Epoch : 0 [4800/35700 (0%)]\tLoss: 0.537105\t Accuracy:79.429%\n",
      "Epoch : 0 [6400/35700 (1%)]\tLoss: 0.208921\t Accuracy:81.965%\n",
      "Epoch : 0 [8000/35700 (1%)]\tLoss: 0.199380\t Accuracy:83.180%\n",
      "Epoch : 0 [9600/35700 (1%)]\tLoss: 0.395419\t Accuracy:84.344%\n",
      "Epoch : 0 [11200/35700 (1%)]\tLoss: 0.017687\t Accuracy:85.372%\n",
      "Epoch : 0 [12800/35700 (1%)]\tLoss: 0.568300\t Accuracy:86.308%\n",
      "Epoch : 0 [14400/35700 (1%)]\tLoss: 0.107166\t Accuracy:86.953%\n",
      "Epoch : 0 [16000/35700 (1%)]\tLoss: 0.828237\t Accuracy:87.344%\n",
      "Epoch : 0 [17600/35700 (2%)]\tLoss: 0.197000\t Accuracy:87.738%\n",
      "Epoch : 0 [19200/35700 (2%)]\tLoss: 0.247744\t Accuracy:88.036%\n",
      "Epoch : 0 [20800/35700 (2%)]\tLoss: 0.043320\t Accuracy:88.402%\n",
      "Epoch : 0 [22400/35700 (2%)]\tLoss: 0.484466\t Accuracy:88.766%\n",
      "Epoch : 0 [24000/35700 (2%)]\tLoss: 0.035722\t Accuracy:89.040%\n",
      "Epoch : 0 [25600/35700 (2%)]\tLoss: 0.094706\t Accuracy:89.295%\n",
      "Epoch : 0 [27200/35700 (2%)]\tLoss: 0.079195\t Accuracy:89.553%\n",
      "Epoch : 0 [28800/35700 (3%)]\tLoss: 0.090461\t Accuracy:89.758%\n",
      "Epoch : 0 [30400/35700 (3%)]\tLoss: 0.273794\t Accuracy:89.974%\n",
      "Epoch : 0 [32000/35700 (3%)]\tLoss: 0.185169\t Accuracy:90.160%\n",
      "Epoch : 0 [33600/35700 (3%)]\tLoss: 0.060359\t Accuracy:90.378%\n",
      "Epoch : 0 [35200/35700 (3%)]\tLoss: 0.141015\t Accuracy:90.540%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.027070\t Accuracy:100.000%\n",
      "Epoch : 1 [1600/35700 (0%)]\tLoss: 0.096444\t Accuracy:94.485%\n",
      "Epoch : 1 [3200/35700 (0%)]\tLoss: 0.056106\t Accuracy:94.864%\n",
      "Epoch : 1 [4800/35700 (0%)]\tLoss: 0.252180\t Accuracy:94.578%\n",
      "Epoch : 1 [6400/35700 (1%)]\tLoss: 0.042158\t Accuracy:94.496%\n",
      "Epoch : 1 [8000/35700 (1%)]\tLoss: 0.022332\t Accuracy:94.397%\n",
      "Epoch : 1 [9600/35700 (1%)]\tLoss: 0.251391\t Accuracy:94.446%\n",
      "Epoch : 1 [11200/35700 (1%)]\tLoss: 0.003491\t Accuracy:94.462%\n",
      "Epoch : 1 [12800/35700 (1%)]\tLoss: 0.270676\t Accuracy:94.498%\n",
      "Epoch : 1 [14400/35700 (1%)]\tLoss: 0.034237\t Accuracy:94.692%\n",
      "Epoch : 1 [16000/35700 (1%)]\tLoss: 0.422021\t Accuracy:94.704%\n",
      "Epoch : 1 [17600/35700 (2%)]\tLoss: 0.063133\t Accuracy:94.686%\n",
      "Epoch : 1 [19200/35700 (2%)]\tLoss: 0.039940\t Accuracy:94.780%\n",
      "Epoch : 1 [20800/35700 (2%)]\tLoss: 0.016703\t Accuracy:94.782%\n",
      "Epoch : 1 [22400/35700 (2%)]\tLoss: 0.282442\t Accuracy:94.807%\n",
      "Epoch : 1 [24000/35700 (2%)]\tLoss: 0.023686\t Accuracy:94.882%\n",
      "Epoch : 1 [25600/35700 (2%)]\tLoss: 0.113664\t Accuracy:94.885%\n",
      "Epoch : 1 [27200/35700 (2%)]\tLoss: 0.041942\t Accuracy:94.973%\n",
      "Epoch : 1 [28800/35700 (3%)]\tLoss: 0.186927\t Accuracy:94.967%\n",
      "Epoch : 1 [30400/35700 (3%)]\tLoss: 0.299719\t Accuracy:95.032%\n",
      "Epoch : 1 [32000/35700 (3%)]\tLoss: 0.172482\t Accuracy:95.036%\n",
      "Epoch : 1 [33600/35700 (3%)]\tLoss: 0.028385\t Accuracy:95.076%\n",
      "Epoch : 1 [35200/35700 (3%)]\tLoss: 0.077839\t Accuracy:95.073%\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "fit(mlp, torch_X_train, torch_y_train, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining `TensorDatset` and `DataLoader`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T15:06:32.666858Z",
     "start_time": "2020-12-07T15:06:32.663078Z"
    }
   },
   "source": [
    "Once we have our `torch.Tensor` objects from numpy arrays we can create `TensorDataset` objects\n",
    "\n",
    "\n",
    "- **`torch.utils.data.TensorDataset(Xtensor,ytensor)`**\n",
    "\n",
    "This type of `TensorDataset` objects can be used for \n",
    "\n",
    "- Wrapping datasets from tensors.\n",
    "- Each sample will be retrieved by indexing tensors along the first dimension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.498010Z",
     "start_time": "2020-12-09T09:59:42.493054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pytorch train and test sets\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.508333Z",
     "start_time": "2020-12-09T09:59:42.500472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.520311Z",
     "start_time": "2020-12-09T09:59:42.514355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]), tensor([5, 9, 5,  ..., 9, 7, 6]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T15:09:13.341380Z",
     "start_time": "2020-12-07T15:09:13.337825Z"
    }
   },
   "source": [
    "Moreover, from a `TensorDataset` we can create our own loader with:\n",
    "    \n",
    "- **`torch.utils.data.DataLoader(Xtensor, batch_size, shuffle)`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.527773Z",
     "start_time": "2020-12-09T09:59:42.525113Z"
    }
   },
   "outputs": [],
   "source": [
    "# data loader\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the train_loader is an iterable with length equal to the number of examples\n",
    "divided by the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.533648Z",
     "start_time": "2020-12-09T09:59:42.529848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1116.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ceil(len(X_train)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.538894Z",
     "start_time": "2020-12-09T09:59:42.535324Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with a `DataLoader` instance\n",
    "\n",
    "Previously we have created an object named `train_loader` that is a `DataLoader` instance.\n",
    "\n",
    "This object can be used to iterate over batches as follows:\n",
    "\n",
    "```python\n",
    "for X_batch, y_batch in train_loader:\n",
    "\n",
    "    var_X_batch = Variable(X_batch).float() \n",
    "    var_y_batch = Variable(y_batch)\n",
    "```\n",
    "\n",
    "Therefore, it facilitates the generation of minibatches during learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.547241Z",
     "start_time": "2020-12-09T09:59:42.541588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader, 1116)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_loader), len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.557572Z",
     "start_time": "2020-12-09T09:59:42.549434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:42.565253Z",
     "start_time": "2020-12-09T09:59:42.559082Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(model, train_loader):\n",
    "    optimizer = torch.optim.Adam(model.parameters())#,lr=0.001, betas=(0.9,0.999))\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    EPOCHS = 2\n",
    "    model.train()\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "            # X_batch.shape -> torch.Size([32, 784])\n",
    "            var_X_batch = Variable(X_batch).float() \n",
    "            # y_batch.shape -> torch.Size([32]) \n",
    "            var_y_batch = Variable(y_batch)\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(var_X_batch)\n",
    "            loss  = error(y_hat, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Total correct predictions\n",
    "            predicted = torch.max(y_hat.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            \n",
    "            #print(correct)\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), \n",
    "                    100.*batch_idx / len(train_loader), loss.data.item(), \n",
    "                    float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:48.897518Z",
     "start_time": "2020-12-09T09:59:42.567022Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/35700 (0%)]\tLoss: 9.593217\t Accuracy:12.500%\n",
      "Epoch : 0 [1600/35700 (4%)]\tLoss: 0.239271\t Accuracy:69.240%\n",
      "Epoch : 0 [3200/35700 (9%)]\tLoss: 0.368648\t Accuracy:77.166%\n",
      "Epoch : 0 [4800/35700 (13%)]\tLoss: 0.574868\t Accuracy:80.567%\n",
      "Epoch : 0 [6400/35700 (18%)]\tLoss: 0.176270\t Accuracy:82.758%\n",
      "Epoch : 0 [8000/35700 (22%)]\tLoss: 0.210147\t Accuracy:83.952%\n",
      "Epoch : 0 [9600/35700 (27%)]\tLoss: 0.299152\t Accuracy:85.164%\n",
      "Epoch : 0 [11200/35700 (31%)]\tLoss: 0.021604\t Accuracy:86.004%\n",
      "Epoch : 0 [12800/35700 (36%)]\tLoss: 0.493868\t Accuracy:86.791%\n",
      "Epoch : 0 [14400/35700 (40%)]\tLoss: 0.173472\t Accuracy:87.354%\n",
      "Epoch : 0 [16000/35700 (45%)]\tLoss: 0.462378\t Accuracy:87.774%\n",
      "Epoch : 0 [17600/35700 (49%)]\tLoss: 0.198763\t Accuracy:88.215%\n",
      "Epoch : 0 [19200/35700 (54%)]\tLoss: 0.456434\t Accuracy:88.556%\n",
      "Epoch : 0 [20800/35700 (58%)]\tLoss: 0.047496\t Accuracy:88.930%\n",
      "Epoch : 0 [22400/35700 (63%)]\tLoss: 0.462011\t Accuracy:89.185%\n",
      "Epoch : 0 [24000/35700 (67%)]\tLoss: 0.040210\t Accuracy:89.514%\n",
      "Epoch : 0 [25600/35700 (72%)]\tLoss: 0.100204\t Accuracy:89.837%\n",
      "Epoch : 0 [27200/35700 (76%)]\tLoss: 0.020294\t Accuracy:90.096%\n",
      "Epoch : 0 [28800/35700 (81%)]\tLoss: 0.403470\t Accuracy:90.271%\n",
      "Epoch : 0 [30400/35700 (85%)]\tLoss: 0.310316\t Accuracy:90.510%\n",
      "Epoch : 0 [32000/35700 (90%)]\tLoss: 0.187865\t Accuracy:90.697%\n",
      "Epoch : 0 [33600/35700 (94%)]\tLoss: 0.086870\t Accuracy:90.875%\n",
      "Epoch : 0 [35200/35700 (99%)]\tLoss: 0.240009\t Accuracy:90.988%\n",
      "Epoch : 1 [0/35700 (0%)]\tLoss: 0.042431\t Accuracy:100.000%\n",
      "Epoch : 1 [1600/35700 (4%)]\tLoss: 0.068518\t Accuracy:94.485%\n",
      "Epoch : 1 [3200/35700 (9%)]\tLoss: 0.043350\t Accuracy:94.647%\n",
      "Epoch : 1 [4800/35700 (13%)]\tLoss: 0.411903\t Accuracy:94.599%\n",
      "Epoch : 1 [6400/35700 (18%)]\tLoss: 0.013385\t Accuracy:94.667%\n",
      "Epoch : 1 [8000/35700 (22%)]\tLoss: 0.024847\t Accuracy:94.547%\n",
      "Epoch : 1 [9600/35700 (27%)]\tLoss: 0.239739\t Accuracy:94.612%\n",
      "Epoch : 1 [11200/35700 (31%)]\tLoss: 0.010886\t Accuracy:94.729%\n",
      "Epoch : 1 [12800/35700 (36%)]\tLoss: 0.223472\t Accuracy:94.724%\n",
      "Epoch : 1 [14400/35700 (40%)]\tLoss: 0.010194\t Accuracy:94.873%\n",
      "Epoch : 1 [16000/35700 (45%)]\tLoss: 0.302165\t Accuracy:94.923%\n",
      "Epoch : 1 [17600/35700 (49%)]\tLoss: 0.019451\t Accuracy:94.947%\n",
      "Epoch : 1 [19200/35700 (54%)]\tLoss: 0.039188\t Accuracy:94.993%\n",
      "Epoch : 1 [20800/35700 (58%)]\tLoss: 0.034125\t Accuracy:95.118%\n",
      "Epoch : 1 [22400/35700 (63%)]\tLoss: 0.067373\t Accuracy:95.177%\n",
      "Epoch : 1 [24000/35700 (67%)]\tLoss: 0.007518\t Accuracy:95.231%\n",
      "Epoch : 1 [25600/35700 (72%)]\tLoss: 0.298082\t Accuracy:95.252%\n",
      "Epoch : 1 [27200/35700 (76%)]\tLoss: 0.095202\t Accuracy:95.322%\n",
      "Epoch : 1 [28800/35700 (81%)]\tLoss: 0.181602\t Accuracy:95.352%\n",
      "Epoch : 1 [30400/35700 (85%)]\tLoss: 0.708822\t Accuracy:95.390%\n",
      "Epoch : 1 [32000/35700 (90%)]\tLoss: 0.051437\t Accuracy:95.395%\n",
      "Epoch : 1 [33600/35700 (94%)]\tLoss: 0.032362\t Accuracy:95.460%\n",
      "Epoch : 1 [35200/35700 (99%)]\tLoss: 0.229418\t Accuracy:95.467%\n"
     ]
    }
   ],
   "source": [
    "fit(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:48.903044Z",
     "start_time": "2020-12-09T09:59:48.899557Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "#model = mlp\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        #print(test_imgs.shape)\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(test_loader)*BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T09:59:49.058166Z",
     "start_time": "2020-12-09T09:59:48.904483Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.945% \n"
     ]
    }
   ],
   "source": [
    "evaluate(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
